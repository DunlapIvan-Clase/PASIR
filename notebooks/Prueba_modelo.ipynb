{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Este notebook ayuda a probar el modelo **LLM** entrenado para clasificar atacantes en análisis de tráfico de red. Para usar el modelo es necesario un entorno con mínimo **50 GB de RAM**, es posible exportar los resultados en un fichero **JSON** o llamar directamente a la **API** del **SIEM** **Wazuh** para almacenar los resultados a modo de eventos.\n",
        "\n",
        "Si se usa en la plataforma Google Colab, es útil montar Google Drive y crear un directorio en el que trabajar, en todo caso deben de consultarse las rutas utilizadas en este ejemplo y adaptarse.\n",
        "\n",
        "\n",
        "\n",
        "*Ivan Dunlap, 2024*"
      ],
      "metadata": {
        "id": "O0v56pD6kQ_P"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 1: instalación de dependencias necesarias en el entorno\n",
        "Para ejecutar este notebook, es necesario instalar varias dependencias. A continuación, se muestra el código para instalar estas dependencias en el entorno de ejecución."
      ],
      "metadata": {
        "id": "lv4IOBXf5olP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EYdLgeEg5bG9"
      },
      "outputs": [],
      "source": [
        "%cd /content/drive/MyDrive/PASIR/model\n",
        "!pip install torch torchvision torchaudio\n",
        "!pip install datasets\n",
        "!pip install transformers\n",
        "!pip install aggregate\n",
        "!pip install accelerate\n",
        "!pip install flash_attn\n",
        "!pip install argparse\n",
        "!pip install -e git+https://github.com/OpenAccess-AI-Collective/axolotl#egg=axolotl\n",
        "!pip install huggingface_hub==0.23.3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 2: autenticación en Hugging Face (ver sección obtención de token)\n",
        "\n",
        "Para utilizar modelos de la plataforma Hugging Face, es necesario obtener un token y logearse."
      ],
      "metadata": {
        "id": "PPmXC9pb51AP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from huggingface_hub import notebook_login\n",
        "notebook_login()"
      ],
      "metadata": {
        "id": "c1QrBMiV5660"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 3: clonar los repositorios necesarios (en caso de no tenerlos ya)\n",
        "\n",
        "Si ya se han clonado anteriormente y se dispone de ellos en el directorio actual, este paso no es necesario."
      ],
      "metadata": {
        "id": "z0ssAcLs6ehO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/dhd2000/DissertationFiles.git\n",
        "!git clone https://github.com/KayvanKarim/ntfa.git\n",
        "!git clone https://github.com/OpenAccess-AI-Collective/axolotl.git\n",
        "!git clone https://github.com/DunlapIvan-Clase/PASIR.git"
      ],
      "metadata": {
        "id": "kH-lkfRO6fpo"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 4: procesar los datos para que sean aceptados por el modelo\n",
        "Este paso es importante para que los datos provenientes tanto de un dataset como el utilizado para entrenar el modelo, Intrusion detection evaluation dataset (CIC-IDS2017) como los datos recogidos por nuestro colector, sean utilzables por el mismo.\n",
        "\n",
        "Es necesario cambiar la ruta y el fichero csv que queramos utilizar para aplicar la transformación.\n",
        "\n",
        "A la hora de ejecutar el script ntfa, si no disponemos de un fichero de configuración json, debemos de configurar el índice de cada columna de nuestro dataset para que el script la reconozca."
      ],
      "metadata": {
        "id": "VYHKUlMR6su5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "# Directorio donde se encuentra el archivo CSV\n",
        "traffic_dir = r'./CIDDS-001/CIDDS-001/traffic/OpenStack'\n",
        "\n",
        "# Nombre del archivo específico a utilizar\n",
        "target_csv_file = 'CIDDS-001-internal-week1.csv'\n",
        "\n",
        "target_csv_path = os.path.join(traffic_dir, target_csv_file)\n",
        "\n",
        "!python3 ntfa/ntfa.py {target_csv_path}\n",
        "!python3 DissertationFiles/convert.py output.csv\n",
        "!python3 DissertationFiles/balance_dataset.py output.jsonl"
      ],
      "metadata": {
        "id": "BINd6ken6zad"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 5: utilizar el modelo mediante el script.\n",
        "\n",
        "Una vez que tengamos los datos, podemos utilizar el script para probar el modelo o para utilizarlo en un entorno real.\n",
        "\n",
        "### Ejemplos de uso del script\n",
        "\n",
        "#### Ejemplo 1: enviar los resultados del modelo a Wazuh mediante la API (ideal para ejecuciones locales)\n",
        "\n",
        "!python3 ../PASIR/traffic_analyzer/traffic_analyzer.py send ruta-fichero-jsonl-generado usuario-api-wazuh pass-api-wazuh host\n",
        "\n",
        "#### Ejemplo 2: almacenar los resultados del modelo en un fichero formato \"JSON\"\n",
        "!python3 ../PASIR/traffic_analyzer/traffic_analyzer.py save ruta-fichero-jsonl-generado ruta-fichero-json-salida\n",
        "\n",
        "\n",
        "#### Ejemplo 3: enviar los datos del fichero \"JSON\" a Wazuh mediante la API\n",
        "!python3 ../PASIR/traffic_analyzer/traffic_analyzer.py sendfile  ruta-fichero-json usuario-api-wazuh pass-api-wazuh host\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "W0Dxu-_u7JtK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/PASIR/model/mistral-NIDS\n",
        "!python3 ../PASIR/traffic_analyzer/traffic_analyzer.py save /content/drive/MyDrive/PASIR/model/output_test.jsonl /content/drive/MyDrive/PASIR/model/traffic_analyzer/output2.json"
      ],
      "metadata": {
        "id": "Ly-4iJOa7Ke4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## PASO 6: utilizar el modelo para crear una estadística de su funcionamiento.\n",
        "\n",
        "Para comprobar el funcionamiento del modelo y crear una estadística de como está funcionando, podemos utilizar este paso, aunque es necesario que los datos que utilicemos se encuentren etiquetados, como los del dataset de entrenamiento."
      ],
      "metadata": {
        "id": "QngdoWjbnanz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "torch.cuda.empty_cache()\n",
        "%cd /content/drive/MyDrive/PASIR/model/mistral-NIDS\n",
        "!cp /content/drive/MyDrive/PASIR/model/DissertationFiles/finetune_test_llama.py ./finetune_test.py\n",
        "!sed -i \"s/NousResearch\\/Llama\\-2\\-7b\\-hf/mistralai\\/Mistral\\-7B\\-v0\\.1/\" ./finetune_test.py # Cambiar modelo base\n",
        "\n",
        "!python3 finetune_test.py /content/drive/MyDrive/PASIR/model/output.jsonl"
      ],
      "metadata": {
        "id": "WsoQKgLhn_Kg"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}